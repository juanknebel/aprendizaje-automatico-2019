{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajo Práctico 2 - Aprendizaje Automático 2019 - Comisión 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de las librería necesarias\n",
    "\n",
    "* sklearn: https://scikit-learn.org/stable/ Machine Learning in Python\n",
    "* pandas: https://pandas.pydata.org/ Python Data Analysis Library\n",
    "* csv: https://realpython.com/python-csv/ Reading and Writing CSV Files in Python\n",
    "* pydotplus: https://pypi.org/project/pydotplus/ Python Interface to Graphviz’s Dot language\n",
    "    Se debe instalar https://www.graphviz.org/ y actualizar Anaconda\n",
    "* matplotlib: https://matplotlib.org/  Python 2D plotting library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leer archivo csv (newdata.csv)\n",
    "Recorre todas las filas del archivo csvfile y lo deja en lista a, en donde cada fila es una lista "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Cantidad de Elementos:  2770\nCantidad de Columnas a traducir:  8\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "data_full = []\n",
    "attributes_location=set()\n",
    "attributes_description=set()\n",
    "attributes_url=set()\n",
    "attributes_verified=set()\n",
    "attributes_lan=set()\n",
    "attributes_default_profile=set()\n",
    "attributes_default_profile_image=set()\n",
    "attributes_has_extended_profile=set()\n",
    "attributes_full=[]\n",
    "\n",
    "with open('../data/newdata.csv','r', encoding=\"utf8\") as csv_file:\n",
    "    reader = csv.reader(csv_file)\n",
    "    headers = next(reader,None)\n",
    "    for row in reader:\n",
    "        data_full.append (row)\n",
    "        attributes_location.add(row[0])\n",
    "        attributes_description.add(row[1])\n",
    "        attributes_url.add(row[2])\n",
    "        attributes_verified.add(row[8])\n",
    "        attributes_lan.add(row[10])\n",
    "        attributes_default_profile.add(row[11])\n",
    "        attributes_default_profile_image.add(row[12])\n",
    "        attributes_has_extended_profile.add(row[13])\n",
    "        \n",
    "attributes_full.append(list(attributes_location))\n",
    "attributes_full.append(list(attributes_description))\n",
    "attributes_full.append(list(attributes_url))\n",
    "attributes_full.append(list(attributes_verified))\n",
    "attributes_full.append(list(attributes_lan))\n",
    "attributes_full.append(list(attributes_default_profile))\n",
    "attributes_full.append(list(attributes_default_profile_image))\n",
    "attributes_full.append(list(attributes_has_extended_profile))\n",
    "\n",
    "\n",
    "print(\"Cantidad de Elementos: \",len(data_full))\n",
    "print(\"Cantidad de Columnas a traducir: \",len(attributes_full))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapeo de categoricos\n",
    "\n",
    "En la matriz ``` data_labeled ``` quedan los datos de entrenamiento.\n",
    "\n",
    "El array ```y_vector_class ``` representa la clase a la que pertenece cada fila del array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def process_to_category(data_raw, attributes_to_category):\n",
    "    num_attributes=len(attributes_full)\n",
    "    y_vector_class=[]\n",
    "    data_labeled=[]\n",
    "\n",
    "    le1 = preprocessing.LabelEncoder()\n",
    "    le2 = preprocessing.LabelEncoder()\n",
    "    le3 = preprocessing.LabelEncoder()\n",
    "    le4 = preprocessing.LabelEncoder()\n",
    "    le5 = preprocessing.LabelEncoder()\n",
    "    le6 = preprocessing.LabelEncoder()\n",
    "    le7 = preprocessing.LabelEncoder()\n",
    "    le8 = preprocessing.LabelEncoder()\n",
    "    le1.fit(attributes_full[0])\n",
    "    le2.fit(attributes_full[1])\n",
    "    le3.fit(attributes_full[2])\n",
    "    le4.fit(attributes_full[3])\n",
    "    le5.fit(attributes_full[4])\n",
    "    le6.fit(attributes_full[5])\n",
    "    le7.fit(attributes_full[6])\n",
    "    le8.fit(attributes_full[7])\n",
    "\n",
    "    for i in range(0,len(data_raw)):\n",
    "        c0=le1.transform(data_raw[i][0:1])[0]\n",
    "        c1=le2.transform(data_raw[i][1:2])[0]\n",
    "        c2=le3.transform(data_raw[i][2:3])[0]\n",
    "        c3=data_raw[i][3:4][0]\n",
    "        c4=data_raw[i][4:5][0]\n",
    "        c5=data_raw[i][5:6][0]\n",
    "        c6=data_raw[i][6:7][0]\n",
    "        c7=data_raw[i][7:8][0]\n",
    "        c8=le4.transform(data_raw[i][8:9])[0]\n",
    "        c9=data_raw[i][9:10][0]\n",
    "        c10=le5.transform(data_raw[i][10:11])[0]\n",
    "        c11=le6.transform(data_raw[i][11:12])[0]\n",
    "        c12=le7.transform(data_raw[i][12:13])[0]\n",
    "        c13=le8.transform(data_raw[i][13:14])[0]\n",
    "        # Hay que armar C no solo con los traducibles sino tambien con los numericos.\n",
    "        data_labeled.append([c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13])\n",
    "\n",
    "    # Separo la ultima columna como vector de resultado.\n",
    "    for i in range(0,len(data_raw)):\n",
    "        y_vector_class.append(data_raw[i][len(data_raw[1])-1])\n",
    "    \n",
    "    return data_labeled, y_vector_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separación en conjuntos de entrenamiento y test\n",
    "\n",
    "``` original_train_x, original_train_y ``` contienen el conjunto principal de los datos de entrenamiento.\n",
    "\n",
    "``` test_X, test_Y ``` son los datos de test que no se van a utilizar hasta el final, para calcular el accuracy de los algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "train_X:  1938\ntrain_y:  1938\ntest_y:  831\ntest_X:  831\n------------------------\ntrain_X:  1550\ntrain_y:  1550\nvalidate_X:  388\nvalidate_y:  388\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "data_labeled, y_vector_class = process_to_category(data_raw=data_full, attributes_to_category=attributes_full)\n",
    "\n",
    "# Se separan los datos en dataFrame\n",
    "# Creo el Data Frame para comenzar a separar en conjuntos de datos\n",
    "dataFrame=pd.DataFrame(data_labeled)\n",
    "\n",
    "original_train_X, test_X, original_train_y, test_y = train_test_split(dataFrame, y_vector_class, \n",
    "                                                   train_size=0.7,\n",
    "                                                   test_size=0.3,\n",
    "                                                   random_state=123)\n",
    "\n",
    "print(\"train_X: \" , len(original_train_X))\n",
    "print(\"train_y: \" ,len(original_train_y))\n",
    "print(\"test_y: \" ,len(test_y))\n",
    "print(\"test_X: \" ,len(test_X))\n",
    "\n",
    "train_X, validate_X, train_y, validate_y = train_test_split(original_train_X, original_train_y, \n",
    "                                                   train_size=0.8,\n",
    "                                                   test_size=0.2,\n",
    "                                                   random_state=123)\n",
    "\n",
    "print(\"------------------------\")\n",
    "print(\"train_X: \" , len(train_X))\n",
    "print(\"train_y: \" ,len(train_y))\n",
    "print(\"validate_X: \" ,len(validate_X))\n",
    "print(\"validate_y: \" ,len(validate_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Calculo de scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_scores(validations, predictions):\n",
    "    acc = accuracy_score(validations, predictions)\n",
    "    tn, fp, fn, tp = confusion_matrix(validations, predictions).ravel()\n",
    "    prec = tp / (tp + fp)\n",
    "    recall = tp / ( tp + fn )\n",
    "    f1 = 2 * ((prec * recall)/(prec + recall))\n",
    "    return acc, tp, fp, fn, tp, prec, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Set del cross validations\n",
    "Si cross_validation == 2, entonces simplemente hace un train y validation\n",
    "\n",
    "Si cross_validation == 5 realiza el clasico k-cross-validation con k == 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "cross_validation = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n                       max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=100,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "estimators = [10, 50, 100]\n",
    "max_depth = [2, 3, 4, 5, None]\n",
    "quality = [\"gini\", \"entropy\"]\n",
    "max_features = [\"sqrt\", \"log2\", None]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "params_rf = {'n_estimators': estimators, \n",
    "             'max_depth': max_depth, \n",
    "             'criterion': quality,\n",
    "             'max_features': max_features,\n",
    "             'bootstrap': bootstrap}\n",
    "\n",
    "random_forest_grid_search = GridSearchCV(RandomForestClassifier(), params_rf, cv=cross_validation)\n",
    "random_forest_model = random_forest_grid_search.fit(original_train_X, original_train_y)\n",
    "\n",
    "random_forest_best = random_forest_grid_search.best_estimator_\n",
    "random_forest_pred = random_forest_model.predict(test_X)\n",
    "rf_acc, rf_tn, rf_fp, rf_fn, rf_tp, rf_prec, rf_recall, rf_f1 = calculate_scores(test_y, random_forest_pred)\n",
    "print(random_forest_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=6,\n                       max_features=None, max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, presort=False,\n                       random_state=None, splitter='best')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "params_dt = {'max_depth': [3, 6, None], 'max_leaf_nodes':[None], 'criterion':[\"gini\", \"entropy\"]}\n",
    "\n",
    "decision_tree_grid_search = GridSearchCV(DecisionTreeClassifier(), params_dt, cv=cross_validation)\n",
    "decision_tree_model = decision_tree_grid_search.fit(original_train_X, original_train_y)\n",
    "\n",
    "decision_tree_best = decision_tree_model.best_estimator_\n",
    "decision_tree_pred = decision_tree_model.predict(test_X)\n",
    "dt_acc, dt_tn, dt_fp, dt_fn, dt_tp, dt_prec, dt_recall, dt_f1 = calculate_scores(test_y, decision_tree_pred)\n",
    "print (decision_tree_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "KNeighborsClassifier(algorithm='ball_tree', leaf_size=30, metric='minkowski',\n                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n                     weights='uniform')\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "params_knn = {'n_neighbors': np.arange(1, 25), 'weights': ['uniform', 'distance'], \n",
    "              'algorithm': ['ball_tree', 'kd_tree', 'brute', 'brute']}\n",
    "\n",
    "knn_grid_search = GridSearchCV(KNeighborsClassifier(), params_knn, cv=cross_validation)\n",
    "knn_model = knn_grid_search.fit(original_train_X, original_train_y)\n",
    "\n",
    "knn_best = knn_model.best_estimator_\n",
    "knn_pred = knn_grid_search.predict(test_X)\n",
    "knn_acc, knn_tn, knn_fp, knn_fn, knn_tp, knn_prec, knn_recall, knn_f1 = calculate_scores(test_y, knn_pred)\n",
    "print(knn_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Regresion logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/zero/.conda/aprendizaje2/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "logistic_model = log_reg.fit(original_train_X, original_train_y)\n",
    "\n",
    "lr_pred = logistic_model.predict(test_X)\n",
    "lr_acc, lr_tn, lr_fp, lr_fn, lr_tp, lr_prec, lr_recall, lr_f1 = calculate_scores(test_y, lr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Votacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "/home/zero/.conda/aprendizaje2/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "estimators=[('knn', knn_best), ('dt', decision_tree_best), ('log_reg', log_reg)]\n",
    "ensemble = VotingClassifier(estimators, voting='hard')\n",
    "\n",
    "ens_model = ensemble.fit(train_X, train_y)\n",
    "ensemble_score = ensemble.score(test_X, test_y)\n",
    "\n",
    "ens_y_pred = ens_model.predict(test_X)\n",
    "\n",
    "ens_acc, ens_tn, ens_fp, ens_fn, ens_tp, ens_prec, ens_recall, ens_f1 = calculate_scores(test_y, ens_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## ADA BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "abc = AdaBoostClassifier(n_estimators=50,\n",
    "                         learning_rate=1,base_estimator=decision_tree_best)\n",
    "\n",
    "ada_model = abc.fit(original_train_X, original_train_y)\n",
    "\n",
    "ada_y_pred = ada_model.predict(test_X)\n",
    "ada_acc, ada_tn, ada_fp, ada_fn, ada_tp, ada_prec, ada_recall, ada_f1 = calculate_scores(test_y,ada_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Gravo las medidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "csv.register_dialect('my_dialect', delimiter = ';', quotechar='\\\"')\n",
    "with open(\"./scores.csv\", \"w\") as csv_file:\n",
    "    writer = csv.writer(csv_file, dialect='my_dialect')\n",
    "    writer.writerow([\"method\",\"accuracy\",\"tn\",\"fp\",\"fn\",\"tp\",\"prec\",\"recall\",\"f1\"])\n",
    "    writer.writerow([\"RandomForest\",rf_acc, rf_tn, rf_fp, rf_fn, rf_tp, rf_prec, rf_recall, rf_f1])\n",
    "    writer.writerow([\"DecisionTree\",dt_acc, dt_tn, dt_fp, dt_fn, dt_tp, dt_prec, dt_recall, dt_f1])\n",
    "    writer.writerow([\"KNN\",knn_acc, knn_tn, knn_fp, knn_fn, knn_tp, knn_prec, knn_recall, knn_f1])\n",
    "    writer.writerow([\"LogisticRegression\",lr_acc, lr_tn, lr_fp, lr_fn, lr_tp, lr_prec, lr_recall, lr_f1])\n",
    "    writer.writerow([\"Ensamble\",ens_acc, ens_tn, ens_fp, ens_fn, ens_tp, ens_prec, ens_recall, ens_f1])\n",
    "    writer.writerow([\"AdaBoost\",ada_acc, ada_tn, ada_fp, ada_fn, ada_tp, ada_prec, ada_recall, ada_f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "knn: 0.7087845968712395\ndt: 0.8892900120336944\nlog_reg: 0.7316486161251504\nrf: 0.8892900120336944\nada: 0.8832731648616126\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print('knn: {}'.format(knn_best.score(test_X,test_y)))\n",
    "print('dt: {}'.format(random_forest_best.score(test_X, test_y)))\n",
    "print('log_reg: {}'.format(log_reg.score(test_X, test_y)))\n",
    "print('rf: {}'.format(random_forest_best.score(test_X, test_y)))\n",
    "print('ada: {}'.format(abc.score(test_X, test_y)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}