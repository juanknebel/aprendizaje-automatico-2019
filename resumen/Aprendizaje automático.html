<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="content-type" content="text/html; charset=utf-8">
<meta name="generator" content="ReText 7.0.1">
<title>Aprendizaje automático</title>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  config: ["MMLorHTML.js"],
  jax: ["input/TeX", "output/HTML-CSS", "output/NativeMML"],
  extensions: ["MathMenu.js", "MathZoom.js"],
  TeX: {
    extensions: ["AMSmath.js", "AMSsymbols.js"],
    equationNumbers: {autoNumber: "AMS"}
  }
});
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js"></script></head>
<body>
<h1>Aprendizaje automático</h1>
<h2>Definición</h2>
<p>Samuel 1959:</p>
<p>Estudia algoritmos para que la computadora aprenda a resolver problemas a partir de un set de datos sin necesidad de programarción específica.</p>
<p>Mitchel 1998:</p>
<p>Un programa de computadora aprende una experiencia E con respecto a una clase de tareas T y una medida de performance P, si su performance en las tareas T, medidas por P, mejoran la experiencia E.</p>
<h3>Ejemplos:</h3>
<ul>
<li>Extracción de información</li>
<li>Detección de promotores (ADN)</li>
<li>Minería de datos</li>
<li>Autos autónomos</li>
<li>Reconocimiento de escritura</li>
<li>Procesamiento del lenguaje natural</li>
<li>Procesamiento de la visión</li>
<li>Sistemas de recomendación</li>
<li>Reconocimiento del habla</li>
<li>Prediccion de tiempo de viaje</li>
<li>Detección de fraude</li>
<li>Publicidad on line</li>
</ul>
<h4>Juego de Go:</h4>
<ul>
<li>Tarea T: juegar al go</li>
<li>Medida de performance P: probabilidad de que el programa gane el siguiente partido.</li>
<li>Experiencia E: la experiencia de jugar muchos jiuegos de go.</li>
</ul>
<h3>Tipos de AA</h3>
<ul>
<li>Supervisado.</li>
<li>No supervisado.</li>
<li>Aprendizaje por refuerzos.</li>
</ul>
<h4>Supervisado</h4>
<p>Problemas de regresión. de clasificación.<br>
Input del algoritmo: set de datos y sus respectivas respuestas.<br>
Tarea del algoritmo: producir nuevas respuestas.<br>
Salida: contínua, numérica, discreta.</p>
<h4>No supervisado</h4>
<p>Clustering, detección de patrones, reducción de la dimensionalidad.</p>
<h4>Por refuerzos</h4>
<p>Juegos de mesa, robots autónomos (secuencia de acciones).<br>
Premios y castigos en función de satisfacción del objetivo.<br>
Con agentes autónomos (sensores) para elegir acciones óptimas que le permitan lograr sus objetivos.</p>
<h2>Disponibilidad de datos</h2>
<p>Big data, footprint.</p>
<h4>Datos</h4>
<ul>
<li>Estructurados:</li>
<li>Numéricos.</li>
<li>Ordinales (tienen orden).</li>
<li>Categóricos (sin orden).</li>
<li>No estructurados.</li>
<li>Semiestructurados.</li>
</ul>
<h3>Calidad de los datos</h3>
<p>Definición es subjetiva. Un dato o conjunto de datos X es de mayor (o mejor) calidad que otro conjunto de datos si el primero satisface las necesidades del usuario mejor que el segundo.</p>
<h4>Consucuencias de los malos datos</h4>
<ul>
<li>Descreimiento.</li>
<li>Insatisfacción de los clientes.</li>
<li>Costos innecesarios.</li>
<li>Impacto en la toma de decisiones.</li>
</ul>
<h4>Dependen de</h4>
<ul>
<li>Calidad del software.</li>
<li>Definición de procesos asociados a los datos.</li>
<li>Diseño de base de datos</li>
<li>Capacitación.</li>
</ul>
<p>Se quiere <strong>datos consistentes y correctos</strong>.</p>
<p>No existen datos perfectos y es necesario priorizar las calidades deseadas.</p>
<h4>Atributos de calidad de los datos</h4>
<ul>
<li>Completitud.</li>
<li>Relevancia.</li>
<li>Vigencia.</li>
<li>Disponibilidad.</li>
<li>Confiabilidad.</li>
<li>Consistencia.</li>
<li>Corrección.</li>
<li>Seguridad y privacidad.</li>
</ul>
<h3>Bias de los datos</h3>
<p>Datos tomados a través de scrapping pueden tener sesgos étnicos o de géneros debido a los origines de los datos y la calidad de las consutlas realizadas.<br>
Se debe saber recolectar, interpretar, organizar, resumir y analizar los datos para poder sacar conclusiones válidas.</p>
<h2>Adquisición de conceptos</h2>
<p>Inducir automáticamente una función booleana a partir de conjuntos de ejemplos de datos (clasificados como positivos o negativos). Dado un nuevo caso devuelve su clase.<br>
Un problema de búsqueda de la hipótesis que más se adecua a los ejemplos mostrados sobre un espacio predefinido de posibles hipótesis.</p>
<ul>
<li>Las hipótesis pertenecen a un <strong>espacion de hipótesis H</strong>.</li>
<li>Puede ocurrir que H no contenga al concepto objetivo.</li>
<li>Algoritmo de aprendizaje: buscar la hipótesis <strong>H</strong> que mejor se ajusta a nuestros datos (D).</li>
</ul>
<h3>Aprendizaje inductivo</h3>
<p>Construir un modelo general a partir de información específica.<br>
Principio: cualquiier hipótesis que aproxime bien a una función objetivo sobre un conjunto suficientemente grande de datos, también aproximará bien a la función objetivo sobre datos no observados.</p>
<h4>Sesgo inductivo (Bias)</h4>
<p>Reduce el espacio de búsqueda, asumiendo que las hipótesis tienen una forma particular. En otras palabras: <strong>reducción de espacio de conceptos grande a uno chico</strong>.</p>
<h4>Relación de orden general - específico</h4>
<p>Relación de orden que existe para todos los problemas de aprendizaje de conceptos. Sean hj y hk funciones booleanas definidas en X, entonces hj es más general que hk (hj&gt;=hk) si y solo si para todo elemento x en X si hk(x) = true entonces hj(x) = true.</p>
<h4>Algoritmos</h4>
<ul>
<li>Find-S.</li>
<li>List-then-eliminate.</li>
<li>CAE (candidate elimination).</li>
</ul>
<h5>Find-S</h5>
<p>Usa orden parcial general-específico. Garantiza:</p>
<ul>
<li>Hipótesis más específica en H consitente con los ejemplos positivos.</li>
<li>Hipótesis consistente con valores negativos.</li>
<li>Encuentra una hipótesis consiste con los datos de entrenamiento.</li>
<li>Puede haber otras hipótesis en H consistentes con los datos.</li>
<li>Prefiere la hipótesis más específica.</li>
<li>No es robusto a ruido.</li>
</ul>
<h5>List-Then-Eliminate</h5>
<p>Espacio de versiones VS: subconjunto de hipótesis de H consistentes con el conjunto de entrenamiento.<br>
Es inmanejable por el tamaño de H.</p>
<h5>CAE</h5>
<p>Espacio de versiones: subconjunto de hipótesis representadas por la más general y la menos general.<br>
Sesgo: no se incluyen todas las posibles hipótesis ya que solo se permiten conjunciones de atributos y no disyunciones.<br>
Sesgo 2: reducción del espacio de conceptos.</p>
<h2>Árboles de decisión</h2>
<ul>
<li>Método para inferencia inductiva.</li>
<li>Aprenden de reglas if-then sobre los valores de los atributos. Predicen valor objetivo en función de las reglas.</li>
<li>Nodo: test sobre un atributo de la instancia.</li>
<li>Rama desde el node: corresponde a un valor para ese atributo.</li>
<li>Representa disyunción de conjunciones sobre los valores de los atributos.</li>
<li>No son sensibles a datos ruidosos.</li>
</ul>
<h3>Cuando usarlos</h3>
<ul>
<li>Instancias representables por pares atributo-valor.</li>
<li>La función objetivo tiene valores de salida discretos.</li>
<li>Se pueden requrir hipótesis disyuntivas.</li>
<li>Posible aumento de entrenamiento ruidoso.</li>
<li>Posibles valores con atributos faltantes.</li>
</ul>
<h3>Algoritmos</h3>
<ul>
<li>ID-3</li>
<li>C4.5</li>
</ul>
<p>Para la elección del mejor atributo se pueden utilizar alguna de las siguientes medidas:</p>
<ul>
<li>Information Gain (Entropía): reducción esperada de entropía por partir ejemplos basados en ese atributo.</li>
<li>Impureza de Gini (Gini Gain): reducción de índice Gini por partir ejemplos basados en ese atributo.</li>
<li>Gain ratio.</li>
<li>otras...</li>
</ul>
<p>Se elije siempre el atributo que tiene el mayor valor para la medida elegida.</p>
<h4>Information Gain</h4>
<p>
<script type="math/tex; mode=display">Entropy(S)\ =\ \sum_{c\ \in\ Clases}\ -p_{c}log_{2}p_{c}</script>
</p>
<p>
<script type="math/tex; mode=display">Gain(S, A)\ =\ Entropy(S)\ - \sum_{v\ \in\ Valores(A)}\ \dfrac{|S_{v}|}{|S|}Entropy(S_{v})</script>
</p>
<p>
<script type="math/tex; mode=display">S_{v}\ =\ \{s\ \in\ S\ |\ A(s)\ =\ v\}</script>
</p>
<h4>Gini Gain</h4>
<p>
<script type="math/tex; mode=display">Gini(S)\ =\ 1\ -\ \sum_{c\ \in\ Clases}(\dfrac{|S_{c}|}{|S|})^{2}</script>
</p>
<p>
<script type="math/tex; mode=display">GiniGain(S, A)\ =\ Gini(S)\ -\ \sum_{v\ \in\ Valores(A)}\dfrac{|S_{v}|}{|S|}Gini(S_{v})</script>
</p>
<p>
<script type="math/tex; mode=display">S_{v}\ =\ \{s\ \in\ S\ |\ A(s)\ =\ v\}</script>
</p>
<h3>Sesgo inductivo</h3>
<ul>
<li>Preferencia por:<ul>
<li>árboles más bajos</li>
<li>atributos con information gain alto cerca de la raíz</li>
</ul>
</li>
<li>Sesgo:<ul>
<li>preferencia: búsqueda incompleta en espacio de hipótesis completo. Sesgo: consecuencia de hipótesis de acuerdo a estrategia de búsqueda. Ej: ID-3.</li>
<li>restricción: búsqueda completa en espacio de hipótesis incompleto. Sesgo: consecuencia de poder expresivo de la representación de hipótesis. Ej: CEA.</li>
</ul>
</li>
<li>Navaja de Occam: prefiere la hipótesis más corta que satisface a los datos.</li>
</ul>
<h3>Overfitting</h3>
<p>Una hipótesis sobreajusta a los datos de entrenamiento si existe otra hipótesis que generaliza mejor.</p>
<p>Se puede medir con la exactitud (Aaccuracy):
<script type="math/tex; mode=display">\dfrac{TP\ +\ TN}{TP\ +\ TN\ +\ FP\ +\ FN}</script>
</p>
<p>Como evitar el overfitting en árboles de decisión:</p>
<ul>
<li>Detener el crecimiento del árbol antes de que clasifique perfectamente a los datos.</li>
<li>Hacer crecer el árbol entero y luego podar (post-prune).</li>
</ul>
<h3>Discretizar valores continuos</h3>
<p>Buscar un umbral t y discriminar en función de si A &lt; t. Ordernar las instancias de menor a myor de A y luego buscar partir la lista de forma de maximizar la reducción de impureza.</p>
<h3>Valores faltantes</h3>
<p>Posibles estrategias:</p>
<ul>
<li>asignar el valor más común entre los datos de entrenamiento.</li>
<li>asignar el valor más común entre los datos de entrenamiento que tienen la misma clasificación.</li>
<li>asignar una probabilidad basada en frecuencias observadas en valores de A en nodo n.</li>
</ul>
<h3>Atributos con costo</h3>
<ul>
<li>Se prefieren árboles que usen atributos de bajo costo y solo usar los de alto costo cuando es necesario.</li>
<li>Modificación en ID-3: se usa el término de costo en medida de selección de atributo:<ul>
<li>Gain(S,A) / costo(A), sesgo: preferencia de atributos menos costos.</li>
</ul>
</li>
</ul>
<h3>Resumen</h3>
<p>Ventajas:</p>
<ul>
<li>Fácil visualización e interpretación.</li>
<li>Se pueden usar atributos categóricos, continuos, binarios.</li>
<li>Fáciles de usar y enteder.</li>
<li>Identificar atributos importantes (análisis exploratorio).</li>
<li>Para usar en clasificación y regresión.</li>
</ul>
<p>Desventajas:</p>
<ul>
<li>Pueden tener overfitting.</li>
<li>Suelen necesitarse ensambles de árboles para tener mejor performance.</li>
</ul>
<h2>Evaluación de modelos</h2>
<p>Una primera idea podría ser utilizar el Accuracy pero resulta ser una mala idea porque el modelo puede memorizar los datos de entrenamiento y medir sobre los datos de entrenamiento tiende a sobreestimar los resultados.</p>
<p>Separar los datos en Desarrollo y Test siempre de manera aleatoria.<br>
Test no se tocan ni utilizan hasta la elección del algoritmo que se utilizará y va a servir para calcualr su accuracy final.<br>
Desarrollo se divide en entrenamiento y validación con un q% para validación.</p>
<h3>Cross Validation</h3>
<p>Para evitar la mala suerte de la separación de los datos de entrenamiento y validación se utiliza <strong>k-Fold Cross Validation</strong> (k = 5 es lo normal).</p>
<p>Se separa en k folds disjuntos del mismo tamaño y se entrena sobre todos menos 1 y sobre ese se valida, se repite hasta utilizar todas convinaciones.</p>
<p>Cada una de las iteraciones se puede aplicar un modelo diferente y estos modelos se obtienen por:</p>
<ul>
<li>Distintos atributos (selección y transformación).</li>
<li>Distintos algoritmops (árboles, LDA,KNN, SVM, ...).</li>
<li>Distintos hiperparámetros de cada algoritmo:<ul>
<li>Information Gain, Gini Gain, ... .</li>
<li>Criterio de parada.</li>
<li>Estrategia de poda.</li>
</ul>
</li>
</ul>
<p>La selección de modelos puede utilizarse mediante un random search o grid search.</p>
<h3>Medidas de performance</h3>
<h4>Matriz de confución</h4>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th>valores reales</th>
<th>valores reales</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td></td>
<td>positivo</td>
<td>negativo</td>
</tr>
<tr>
<td>predicción</td>
<td>positivo</td>
<td>TP</td>
<td>FP</td>
</tr>
<tr>
<td>predicción</td>
<td>negativo</td>
<td>FN</td>
<td>TN</td>
</tr>
</tbody>
</table>
<p>El accuracy no dice nada sobre los tipos de aciertos y de errores que tiene el modelo.</p>
<p>
<script type="math/tex; mode=display">Accuracy\ =\ \dfrac{TP\ +\ TN}{TP\ +\ TN\ +\ FP\ +\ FN}</script>
</p>
<p>Precisión de las instancias clasificadas como positivas, cuántas son (cuan útiles son los resultados de búsqueda).</p>
<p>
<script type="math/tex; mode=display">Precision\ =\ \dfrac{TP}{TP\ +\ FP}</script>
</p>
<p>Recall o cubrimiento de las instancias positivas, cuántas fueron clasificadas como positivas (cuan completos son los resultados).</p>
<p>
<script type="math/tex; mode=display">Recall\ =\ \dfrac{TP}{TP\ +\ FN}</script>
</p>
<p>Sensitivy/TPR: pacientes enfermos correctamente diagnosticados. Proporción de usuarios válidos autenticados. <strong>True Positive Rate</strong>.</p>
<p>
<script type="math/tex; mode=display">\dfrac{TP}{TP\ +\ FN}</script>
</p>
<p>Specificity: porcentaje de pacientes sanos correctamente diagnosticados. <strong>Tue Negative Rate</strong>.</p>
<p>
<script type="math/tex; mode=display">\dfrac{TN}{TN\ +\ FP}</script>
</p>
<p>FPR: proporción de impostores que aceptamos erróneamente.</p>
<p>
<script type="math/tex; mode=display">\dfrac{FP}{FP\ +\ TN}</script>
</p>
<h3>Curva ROC</h3>
<p>Gráfico TPR (Recall) vs FPR</p>
<p>En la coordenada x pongo el valor del fpr y en la coordenada y pongo el valor del tpr para todos los modelos que evalué.<br>
Modelos más sobre el eje y es porque necesito priorizar el TPR y más arriba pero lejos del eje y porque acepto que haya más fpr.<br>
Luego dependiendo del problema que estoy queriendo resolver elijo cual me conviene.</p>
<h4>Área bajo la curva AUC</h4>
<p>Siempre elijo aquella curva que me deja más área.</p>
<h2>Naive Bayes</h2>
</body>
</html>
